[{"content":"Introdução Hoje gostaria de propor fazer algo um pouco diferente por aqui, ao invés de explicar algum conceito, eu gostaria de compartilhar como resolvi uma dor no meu trabalho, pois acredito que essa solução possa ajudar iniciantes no SQL com conceitos mais avançados, e pode até auxiliar usuários mais experientes que nunca tenham pensado em fazer algo assim.\nO Airflow é constituído de quatro elementos principais: Worker, Scheduler, Webserver e Database. Este último é um banco de metadados do Airflow, inicialmente construído em SQLite, mas normalmente portado para MySQL ou PostgreSQL, que é, inclusive, o motor em que me basearei para a construção da query. Nesse banco, estão as principais informações de metadados do Airflow, ou seja, dados sobre a própria ferramenta.\nO schema dessas tabelas de metadados está disponível na documentação, mas, uma tabela é especialmente importante para a nossa tarefa: Dag. Nela, estão contidos os dados como o CRON da DAG e se ela está ativa e pausada.\nMas aí que está, nós, humanos, conseguimos interpretar um código CRON com facilidade (depois de um pouco de prática), mas consultar na tabela de metadados quais são as DAGs que são executadas em um horário específico é um desafio. Nisso surge a query que quero desenvolver hoje.\nExpressões CRON Pra quem nunca teve contato, o código CRON (ou apenas CRON) pode ser um pouco intimidador, mas é, na verdade, bem simples: é um código que sintetiza a informação de frequência de atualização de uma tarefa em uma string com 5 informações, em ordem:\nO Minuto de execução. A Hora de execução. O Dia (do mês) de execução. O Mês de execução. O Dia (da semana) de execução. Sendo que qualquer um desses pode ser ocupado por uma das três opções:\nA. Valores específicos (separados por vírgula)\nB. Faixas de valores (separadas por hífen)\nC. Qualquer valor (representado pelo asterisco)\nD. Frequências (representado por um número (ou o asterisco) dividido por outro número)\nA melhor forma de explicar, nesse caso, é com exemplos.\nVamos criar um CRON que execute todos os dias, às 09:20h e às 18:20: Como a ativação acontece todos os dias, qualquer valor para o dia do mês, dia da semana e mês são considerados, portanto preenchemos eles com o asterisco. A hora e o minuto, por outro lado, são valores específicos:\nMinuto: 20 Hora: 9,18 Dia (do mês): * Mês: * Dia (da semana): * E, portanto, escrevemos o CRON da seguinte forma:\n20 9,18 * * * Agora um exemplo um pouco mais completo: a ação deve ser executada todas as segundas-feiras, no início de cada hora par à partir das 06 da manhã. Nesse caso, precisamos colocar segunda-feira no último espaço (os dias da semana começam no domingo, cujo valor é 0, e terminam no sábado, valor 6), porém o dia do mês e o mês podem ser mantidos como \u0026ldquo;qualquer valor\u0026rdquo;. Para fazer essa execução periódica, usamos a barra, portanto escrever */2 equivale à dizer \u0026ldquo;começando no zero, execute à cada duas horas\u0026rdquo;, mas desejamos começar às 06h, portanto, basta substituir o asterisco por 6:\nMinuto: 0 Hora: 6/2 Dia (do mês): * Mês: * Dia (da semana): 1 Ou, no formato de CRON:\n0 6/2 * * 1 Esse básico é suficiente pra gente começar a desenvolver a query, mas existem mais exemplos complexos e outras possibilidades. Para testar o seu entendimento, é possível utilizar o site Crontab Guru para consultar o significado de diferentes códigos.\nA query Como disse, o CRON é uma síntese, ele transmite uma informação em um formato denso, o que, nesse caso, facilita a interpretação humana, mas dificulta a consulta. Imagine, por exemplo, a dor de cabeça que é pra ordenar uma lista de tarefas em ordem de execução.\nDe forma manual você precisa identificar todas as tarefas, traduzir as expressões para frequência de atualização e organizar. Mas, principalmente em uma operação madura, são centenas de DAGs, muito além do que qualquer engenheiro consegue manter na caixola. Pois então surge a necessidade de ser capaz de criar um código capaz de organizar a tal tabela de de metadados do Airflow, ordenando as DAGs em relação à ordem de execução delas!\nComeçando do começo: precisamos garantir que todos as colunas sejam, de fato, códigos CRON. Como a tabela de metadados é gerada automáticamente pelo Airflow, não precisamos nos preocupar com valores nulos ou erros de digitação (a não ser que esteja errado na DAG também, mas isso acho que é um problema maior), apesar disso o Airflow possui algumas expressões simplificadas, escritas em inglês. O primeiro passo é traduzi-las:\nExpressão CRON correspondente Interpretação @once - Uma única vez @hourly 0 * * * * De hora em hora @daily 0 0 * * * Todo dia @weekly 0 0 * * 0 Toda semana @monthly 0 0 1 * * Todo mês @yearly 0 0 1 1 * Uma vez ao ano Para fazer isso, eu uso um CASE-WHEN simples:\nSELECT dag_id, CASE WHEN schedule_interval = \u0026#39;@once\u0026#39; THEN null WHEN schedule_interval = \u0026#39;@hourly\u0026#39; THEN \u0026#39;0 * * * *\u0026#39; WHEN schedule_interval = \u0026#39;@daily\u0026#39; THEN \u0026#39;0 0 * * *\u0026#39; WHEN schedule_interval = \u0026#39;@weekly\u0026#39; THEN \u0026#39;0 0 * * 0\u0026#39; WHEN schedule_interval = \u0026#39;@monthly\u0026#39; THEN \u0026#39;0 0 1 * *\u0026#39; WHEN schedule_interval = \u0026#39;@yearly\u0026#39; THEN \u0026#39;0 0 1 1 *\u0026#39; ELSE schedule_interval END AS schedule_interval FROM dag Note que o código é uma string!\nComo a query vai ficar bem extensa, vou focar apenas nas duas colunas imediatamente relevantes: dag_id, que é o nome da DAG, e schedule_interval, que é o CRON, mas posteriormente, quando formos discutir o uso real dessa query, algumas outras colunas serão importantes, como a informação sobre se a DAG está ativa ou despausada.\nAgora que garantimos que a coluna está homogênea, podemos transformá-la!\nFelizmente, as expressões são separadas por espaços sempre, então nós podemos usar isso à nosso favor: a função split_part, do PostgreSQL, recebe três parâmetros:\nsplit_part( coluna, -- Nome da coluna a ser separada separador, -- Caracter utilizado para fazer a separação posição -- Posição do fragmento que você quer recuperar ) Como já disse antes, as expressões CRON são formadas por cinco espaços. então repetimos essa função cinco vezes, para recuperar cada uma das informações. Outra informação que comentei é que, além do asterisco, também podemos encontrar a barra, \\, a vírgula, , e o hífen -.\nLidaremos com a barra e o hífen depois, mas a vírgula será relevante imediatamente.\nEmbora, sim, estamos representando uma frequência no tempo e ordenaremos a lista de DAGs conforme a sua próxima execução, optei por não tratar as unidades de tempo como unidades de tempo, mas sim como números inteiros, INTEGER. Mais do que isso: listas de números inteiros. E aí que vem o pulo do gato, para fazer a query funcionar, a gente precisa decompor cada uma dessas cinco informações nas listas de números que elas estão tentando emular!\nNo caso em que a informação é um conjunto de valores específicos, fica mais fácil, já que o elefantinho azul nos fornece uma função relevante pra isso: string_to_array. Como o nome sugere, uma string é transformada em uma lista, usando um separador, caso não exista nenhuma instância desse separador na string, o retorno é uma lista unitária.\nstring_to_array( coluna, -- Coluna à ser dividida, de tipo textual separador -- Caracter utilizado para fazer a separação ) Note que a resposta dessa função é sempre uma lista textual, e nem adianta tentar transformar ele numa lista de inteiros ainda, porque a maioria dos elementos serão listas unitárias com asteriscos, {*}. Pois então, pra segunda fase da transformação, temos:\nWITH base AS ( SELECT dag_id, schedule_interval, string_to_array(split_part(schedule_interval, \u0026#39; \u0026#39;, 1), \u0026#39;,\u0026#39;) as minuto, string_to_array(split_part(schedule_interval, \u0026#39; \u0026#39;, 2), \u0026#39;,\u0026#39;) as hora, string_to_array(split_part(schedule_interval, \u0026#39; \u0026#39;, 3), \u0026#39;,\u0026#39;) as dia_mes, string_to_array(split_part(schedule_interval, \u0026#39; \u0026#39;, 4), \u0026#39;,\u0026#39;) as mes, string_to_array(split_part(schedule_interval, \u0026#39; \u0026#39;, 5), \u0026#39;,\u0026#39;) as dia_semana, FROM (SELECT dag_id, CASE WHEN schedule_interval = \u0026#39;@once\u0026#39; THEN null WHEN schedule_interval = \u0026#39;@hourly\u0026#39; THEN \u0026#39;0 * * * *\u0026#39; WHEN schedule_interval = \u0026#39;@daily\u0026#39; THEN \u0026#39;0 0 * * *\u0026#39; WHEN schedule_interval = \u0026#39;@weekly\u0026#39; THEN \u0026#39;0 0 * * 0\u0026#39; WHEN schedule_interval = \u0026#39;@monthly\u0026#39; THEN \u0026#39;0 0 1 * *\u0026#39; WHEN schedule_interval = \u0026#39;@yearly\u0026#39; THEN \u0026#39;0 0 1 1 *\u0026#39; ELSE schedule_interval END AS schedule_interval FROM dag) AS tradutor_cron) Para fechar o pacotinho eu peguei aquele primeiro segmento do código e coloquei dentro de uma subquery, pra poder fazer a consulta em cima dele. Notem que, além disso, adicionei todo o código à uma CTE, para reduzir o tamanho do código. Isso significa que todo esse segmento de código agora é \u0026ldquo;funcionalmente\u0026rdquo; uma tabela, que será chamada usando o nome base, me permitindo omitir esse pedaço.\nAgora, não tem mais pra onde correr, precisamos falar dos outros casos, e isso inclui dois tópicos mais avançados: RegEx e Geradores. Caso você não conheça muito de RegEx, recomendo a leitura de um texto que escrevi aqui no blog, que faz uma introdução bem suave ao tópico. Sobre os geradores, vou fazer uma breve introdução:\nO PostgreSQL (bem como outros motores de SQL) é capaz de gerar listas de alguns tipos de variáveis, como datas e, mais importante no nosso caso, números, usando os geradores, ou funções que retornam listas, a anatomia dessas funções é simples:\ngenerate_series( start, -- Início da lista stop, -- Fim da lista step -- Passo da lista ) Setando, por exemplo, start = 1, stop = 5 e step = 1 (ou vazio, visto que 1 é o valor padrão), iríamos gerar a lista {1,2,3,4,5}. Eu já passei o mandrake do código, iremos decodificar as informações em listas de inteiros, pois bem, essas listas são (ou, pelo menos, começam sendo) todos os valores possíveis que aquela informação pode tomar: dentre uma hora, existem 60 minutos, isso significa que a informação \u0026ldquo;Minuto\u0026rdquo; pode tomar os valores 0, 1, 2,\u0026hellip;, 58, 59. Isso pode ser desenvolvido muito facilmente usando a função generate_series:\nWITH lista_auxiliar_minutos AS ( SELECT generate_series(0, 59) as auxilair ) Para as demais unidades de tempo, a simplicidade se mantém: basta entender quais são os valores possíveis que aquela unidade de tempo pode assumir e gerar uma série com isso. Aqui, porém, surge o maior problema em usar números, ao invés de datas: no dia do mês, a lista gerada é de 1 a 31, porém, obviamente, nem todos os meses têm 31 dias. Isso significa que essa solução é apenas aproximada. A depender de como você vai usar esse código, isso não vai te impactar, mas, é uma limitação importante de se ter em mente!\nContinuando as demais listas:\nlista_auxiliar_horas AS ( SELECT generate_series(0,23) as aux ), lista_auxiliar_dias_mes AS ( SELECT generate_series(1,31) as aux ), lista_auxiliar_meses AS ( SELECT generate_series(1,12) as aux ), lista_auxiliar_dias_semana AS ( SELECT generate_series(0,6) as aux -- 0 é domingo. ), Note que eu gerei, mais uma vez, essas listas em CTEs. Fiz isso por um motivo bastante pessoal: a aplicação que eu usei pra fazer essa consulta não tinha acesso de administrador ao banco, isso significa que ela não poderia criar funções, que seriam a forma como eu preferiria fazer todas essas transformações (ficaria bem mais organizado). O código seria o mesmo, apenas a estrutura que seria mais organizada!\n","permalink":"https://pfalcao97.githubpages.io/blog/posts/airflow_sql/","summary":"Introdução Hoje gostaria de propor fazer algo um pouco diferente por aqui, ao invés de explicar algum conceito, eu gostaria de compartilhar como resolvi uma dor no meu trabalho, pois acredito que essa solução possa ajudar iniciantes no SQL com conceitos mais avançados, e pode até auxiliar usuários mais experientes que nunca tenham pensado em fazer algo assim.\nO Airflow é constituído de quatro elementos principais: Worker, Scheduler, Webserver e Database.","title":"Consultando DAGs por horário no SQL"},{"content":"Introdução A matemática é lógica, por definição. Mas isso não significa que ela seja óbvia e, muito menos, intuitiva. Inclusive, muitas vezes, ela é tão pouco óbvia e intuitiva, que nos parece não-lógica. E isso, por si só, é nada intuitivo!\nTanto é, que existe um campo de estudo inteiro dedicado a tratar o ser humano como ente plenamente lógico e racional - a economia - que foi virado de cabeça pra baixo quando dois psicólogos chegaram e falaram \u0026ldquo;Ei, galera, não é bem assim\u0026hellip;\u0026rdquo;. A revolução foi tão profunda que mereceu até um prêmio Nobel.\nHoje eu quero falar um pouco de algumas falácias lógicas que nos levam a conclusões erradas, a partir de premissas enviesadas, mesmo sem perceber, e uma ferramenta que pode nos ajudar a interpretar o mundo nessas condições, a estatística bayesiana.\nLógica Definição do minidicionário da língua portuguesa, Silveira Bueno:\nLógica: (Substantivo feminino)\nCiência que estuda as leis do raciocínio; coerência; raciocínio.\nExistem muitas palavras que têm uma definição clara, porém o uso no dia-a-dia acaba raptando e transformando seu significado. Lógica é uma dessas. A expressão \u0026ldquo;É lógico\u0026rdquo;, ao invés de significar \u0026ldquo;tem coerência com as premissas básicas adotadas no seu raciocínio\u0026rdquo;, é normalmente utilizada para definir algo que é óbvio, elementar.\nMas essas duas coisas (o óbvio e o coerente) não têm, necessariamente, algo em comum. Não me leve a mal: deveriam ter, mas, quantas vezes você já teve certeza de algo? Pode ser algo que compõe fundamentalmente sua maneira de ver o mundo, como uma ideologia política, ou algo trivial, como a certeza de que seu amigo está te evitando.\nE quantas dessas vezes a certeza se desintegrou depois de uma explicação? Seu amigo não estava te evitando, ele só estava ocupado no trabalho e, portanto, não conseguiu responder os 20 tik toks que você mandou para ele no período de 2 horas, no meio da tarde.\nA própria prática da psicoterapia está muito calcada nisso: às vezes, só de colocar seus pensamentos (que parecem óbvios e corretos) em palavras, você consegue identificar premissas erradas e saltos lógicos. Mas nem sempre esse reconhecimento é fácil.\nImagine a seguinte descrição de uma mulher, Linda:\nLinda tem 31 anos de idade, é solteira, franca e muito inteligente. É formada em filosofia. Quando era estudante, preocupava-se profundamente com questões de discriminação e justiça social, e também participava de manifestações antinucleares.\nApós ler essa descrição, você deve inferir qual sobre a sua situação atual: Será que ela trabalha como professora? Será que é banqueira, ou trabalha numa livraria? Ela participa do movimento feminista? Ela faz ioga?\nDiante de várias opções, muitas pessoas atribuem uma probabilidade maior a Linda ser uma banqueira feminista do que apenas uma banqueira. Ou seja, o estereótipo criado na sua descrição, uma pessoa mais alinhada com ideais progressistas, é tão forte que faz com que muitos ignorem a regra lógica de que para ser feminista e banqueira, ela deve, necessariamente, ser banqueira, por mais que te pareça muito mais provável que ela seja feminista, do que banqueira.\nAssim surge a falácia da conjunção: o ato de considerar eventos conjugados como mais prováveis do que qualquer um dos eventos individuais que o compõe, em uma comparação direta. Ninguém diz que é mais provável tirar cara e depois coroa, ao lançar uma moeda duas vezes, do que tirar só cara, ao lançar uma única vez, mas quando damos uma contextualização maior ao problema, a estatística se confunde com os nossos vieses.\nEssa foi uma das descobertas da dupla de psicólogos, Daniel Kahneman e Amos Tversky.\nAo longo de uma frutífera carreira científica, eles desenvolveram inúmeros experimentos e, com eles, artigos, que iriam quebrar muitos dos paradigmas das ciências comportamentais. Seus trabalhos são extremamente influentes até hoje e foram premiados com o Nobel de Economia em 2002 - Por conta do falecimento de Amos em 1996, Daniel recebeu o prêmio sozinho.\nRápido e Devagar ✏️ Mais recentemente, Daniel escreveu o livro Rápido e Devagar, que virou um best-seller, contando sobre o seu entendimento do funcionamento da mente à partir de todo arcabouço que a psicologia cognitiva desenvolveu desde então - sempre muito bem ilustrado com exemplos tirados diretamente dos seus experimentos, como é o caso da Linda!\nTambém é o caso do experimento que me motivou a escrever o texto: A escolha profissional de Tom W..\nEm alguns lugares no exterior, como nos Estado Unidos, ao final do Ensino Médio, é comum que professores escrevam cartas de recomendação para universidades, descrevendo as qualidades de um aluno particular - Esperançosamente motivando sua entrada em tal universidade. Eis um trecho de uma dessas cartas que foi escrita para um aluno em particular, Tom W.:\nTom é dotado de grande inteligência, embora careça de criatividade genuína. Tem necessidade de ordem e clareza e de sistemas claros e ordenados em que cada detalhe encontre seu lugar apropriado. Seu texto está mais para maçante e mecânico, animado ocasionalmente por alguns trocadilhos batidos e lampejos de imaginação do tipo ficção científica. Exibe forte compulsão por competência. Parece apresentar pouca compreensão e pouca simpatia pelas outras pessoas,e não aprecia a interação com os outros. Autocentrado, exibe no entanto um profundo senso moral.\nNão há nada de especial em Tom, ele foi um aluno escolhido aleatoriamente em uma universidade, para exemplificar o experimento. A universidade que ele estuda oferece os seguintes cursos:\nAdministração Ciência da computação Engenharia Humanidades e educação Direito Medicina Biblioteconomia Ciências físicas e biológicas Ciência social e assistência social Se você tivesse que ordenar os cursos acima, do mais provável para o menos provável de ser o curso de Tom, como ficaria sua lista?\nSupondo que você tenha realmente listado (e eu espero que sim, pois é uma boa forma de entender o que será explicado a seguir), pode ter acontecido duas coisas:\nVocê ordenou com base no estereótipo do curso e no texto do professor. Você não ordenou, porque está faltando uma informação. Rápido e devagar é como Daniel descreve os dois sistemas que agem no nosso cérebro, o sistema 1 é rápido e automático, o sistema 2 é lento e deliberado. Se você respondeu da primeira forma, você usou o sistema 1 para substituir a pergunta, ao invés de responder a pergunta (difícil) da probabilidade por curso, o seu cérebro escolheu responder a pergunta (fácil) de \u0026ldquo;qual desses cursos tem o estereótipo que mais corresponde com a personalidade descrita?\u0026rdquo;. Enquanto que, para responder a pergunta corretamente, seria necessário saber as taxas de incidência de cada curso na universidade, que é o que você deve ter pensado, caso tenha respondido da segunda forma - usando seu sistema 2!\nE antes de você considerar a conclusão acima injusta, veja a seguinte questão, bastante similar:\nEu tenho um pote com 100 bolinhas, na seguinte distribuição: 10 bolinhas vermelhas, 40 bolinhas verdes e 50 bolinhas azuis. Ordene as cores da mais provável para a menos provável de ser a cor de uma bolinha tirada ao acaso.\nSe você tiver um conhecimento básico de probabilidade, deve ter feito a seguinte lista: Azul (50% de probabilidade), Verde (40%) e Vermelho (10%). Por que com Tom W. seria diferente? Você nem sabe se a descrição do professor é certeira!\nO prognóstico por representatividade é a forma como nós focamos nas representações individuais, em detrimento da distribuição de ocorrência do fenômeno. É claro que a descrição individual pode fornecer informações importantes, mas ainda assim, ao invés de substituir a probabilidade basal, o ideal é que ela a atualize.\nA estatística Bayesiana Vamos voltar ao exemplo das bolinhas. A distribuição das cores no pote é a mesma, mas, dentre as bolinhas vermelhas, 80% têm uma linha preta desenhada, dentre as verdes, 40% têm a mesma linha, e dentre as azuis, apenas 20%.\nSe eu adicionar que a bolinha tirada também possui o mesmo desenho, como isso muda a ordem de cores mais prováveis? Bom, vamos fazer uma contagem:\nExistem 8 bolinhas vermelhas com listras (80% de 10). Existem 16 bolinhas verdes com listras (40% de 40). Existem 10 bolinhas azuis com listras (20% de 50). Então, agora nosso espaço amostral não é mais 100, mas 34 (8+16+10), e a ordem deve ser: Verde (47% de probabilidade), Azul (29,5%) e Vermelho (23,5%). A presença da listra não descartou completamente a distribuição de cores anterior - apenas atualizou as probabilidades. O mesmo deveria ter acontecido com Tom.\nDigamos que no ano de entrada de Tom na faculdade existam 200 alunos de administração e 20 de Engenharia, por mais que a descrição de Tom seja compatível com 100% dos estudantes de engenharia (nota do autor: posso confirmar) e apenas 10% dos estudantes de administração - a probabilidade ainda é 50/50, porque representam 20 estudantes de engenharia e 20 de administração!\nÉ justamente esse princípio básico que norteia toda a estatística bayesiana.\nThomas Bayes foi um pastor presbiteriano inglês que viveu no século XVIII. Entre rezas, o professo desenvolveu uma teoria para a probabilidade condicional, ou seja, como saber a probabilidade de que algo aconteça, sabendo que uma outra coisa já aconteceu. Formulando matematicamente o Teorema de Bayes, ficaria assim:\n$$ P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$$\nOu, em português: A probabilidade de que aconteça o evento A, sabendo que já aconteceu o evento B, P(A|B), é igual à probabilidade de que aconteça A, P(A), vezes a probabilidade de que aconteça B, dado que A já aconteceu, P(B|A), dividido pela probabilidade de que aconteça B, P(B). Podemos pensar na fórmula como uma proporção: De todas as vezes que B acontece, quantas acontecem depois de A? Pegue esse número e multiplique pela probabilidade de A, chegando assim ao valor atualizado!\nPode parecer confuso, explicando assim, mas a gente acabou de fazer esse exato exemplo, com as bolinhas coloridas.\nVamos reorganizar o enunciado, para ficar mais claro:\nQual a probabilidade de que uma bolinha com listras, escolhida aleatoriamente do pote, seja azul?\nAplicamos Bayes!\nP(azul|listra): esse é o valor que queremos encontrar, a probabilidade de que uma bolinha listrada seja azul. P(azul): anteriormente vimos que, das 100 bolinhas no pote, 50 são azuis. Portanto essa probabilidade é 50%. P(listra|azul): aqui, queremos saber qual a probabilidade de que uma bolinha azul seja listrada. Isso também foi dado pelo problema, como apenas 20% das bolinhas azuis são listradas, essa probabilidade é, também, 20%. P(listra): As bolinhas listradas são 8 vermelhas, 16 verdes e 10 azuis - 34 no total. Portanto, dividimos pelo número total de bolinhas, 100, e encontramos que essa probabilidade é de 34%. Basta colocar tudo na fórmula acima e voilà!\n$$ P(azul|listra) = \\frac{P(listra|azul) P(azul)}{P(listra)} = \\frac{0,2 \\times 0,5}{0,34} = 0,294 $$\nParabéns, você acabou de reencontrar o mesmo número, só que de forma muito mais difícil. Brincadeiras a parte, não é a toa que o teorema de Bayes é chamado de \u0026ldquo;bom senso aplicado à matemática\u0026rdquo;, é uma boa forma de garantir que seu pensamento é coerente - particularmente nos casos mais complicados de fazer uma verificação simples!\nXKCD Nº 1132: Frequentistas vs. Bayesianos. Verdadeiramente, bom senso aplicado.\nUm bom caso de estudo para esse ramo da estatística está relacionado aos testes médicos, como os testes de COVID, que tanto nos acostumamos a fazer nos últimos anos. Mas não é só nisso que o bom pastor pode te ajudar, ele também pode aumentar suas chances de conseguir um carro novo*!\n* Essa situação é bastante específica, qualquer não obtenção de um veículo novo não é responsabilidade do autor ou do pastor.\nComo interpretar um teste positivo? Temos o costume de ver testes médicos como sentenças: Se o resultado deu positivo, nós temos a doença ou condição que o exame estava testando. Mas isso não é tão preto no branco - tanto é que médicos normalmente pedem para você repetir exames com resultados inesperados, em especial para condições que tenham consequências mais graves.\nNormalmente, nós só pensamos em um único número, a acurácia do teste, mas, no fundo, durante os testes clínicos são computados quatro números relevantes:\nVerdadeiro Falso Positivo O teste identificou a doença corretamente O teste identificou a doença erroneamente Negativo O teste não identificou a doença quando não deveria O teste não identificou a doença quando deveria Em especial, focamos em testes sensíveis: é melhor um alarme falso, resolvido facilmente com um segundo teste, do que não identificar casos em que a doença está presente, agravando o quadro. Isso gera um número de Falsos Positivos comumente maior do que o número de Falsos Negativos e, ambos, se tudo estiver certo, bastante menores do que os resultados verdadeiros.\nPense em uma doença que afete 1 a cada 1000 pessoas no seu grupo - Doenças raramente podem ser tratadas como homogêneas na população. Poderíamos, de forma simplificada, assumir que você tem 1/1000 chances de pegar a doença, portanto a probabilidade de você estar com a doença é de 0,1%. Mas a médica que está te atendendo é uma pessoa cautelosa, e te pede para fazer um teste mesmo assim.\nLendo o manual de uso, você vê que os testes clínicos foram feitos em 2000 pessoas, das quais 50 estavam doentes. Nesses testes, a sensibilidade foi de 96% e a especificidade foi de 90%. Após uma rápida pesquisa, você vê que sensibilidade é uma outra palavra para o Verdadeiro Positivo e especificidade, outra palavra para Verdadeiro Negativo, então, você reconstrói a tabela com os números do teste:\nVerdadeiro Falso Positivo 0,96 (Sensibilidade) 0,1 (1 - Especificidade) Negativo 0,90 (Especificidade) 0,04 (1 - Sensibilidade) Note que a probabilidade de ser verdadeiro ou falso deve ser 100%, por isso que a taxa de falsos negativos deve ser 100% menos a sensibilidade. Isso pode ficar mais claro usando números: Se o teste tem uma taxa de verdadeiros positivos de 96%, significa que das 50 pessoas que estão doentes, o teste irá identificar corretamente 48 e deixará de identificar 2, fazendo com que essas sejam as falsas negativas, conta similar ocorre para a especificidade.\nVerdadeiro Falso Positivo 48 pessoas 195 pessoas Negativo 1.755 pessoas 2 pessoas Depois de fazer o mise en place, você faz o teste e verifica que ele dá positivo. Em qual grupo você está? No das 48 pessoas que realmente têm a doença, ou na das 195 que não têm? Bom, isso quem irá dizer é a profissional da saúde, mas você pode aquietar um pouco a ansiedade, atualizando aquela probabilidade de 0,1% usando a fórmula de Bayes: Qual a probabilidade de que você esteja doente, ao receber um teste positivo, P(doente|positivo)?\nP(doente): essa é a probabilidade que chamamos à priori, ou seja, antes do teste. Nesse caso era de 0,1%. P(positivo|doente): Aqui tratamos da probabilidade de, estando doente, seu teste ser positivo - Em outras palavras, a sensibilidade do teste: 96%. P(positivo): Por fim, a probabilidade do teste dar positivo. Aqui é útil a construção da tabelinha: Dos 2.000 voluntários, 48 foram verdadeiros positivos e 195, falsos positivos, portanto a probabilidade é (48 + 195)/2000, 12,15%. Assim, aplicando os números à fórmula:\n$$ P(doente|positivo) = \\frac{P(positivo|doente) P(doente)}{P(positivo)} = \\frac{0,96 \\times 0,001}{0,1215} = 0,0079 $$\nOu seja, embora o teste aumente em quase 8 vezes sua chance de ter a doença, a grande proporção de falsos positivos para verdadeiros positivos significa que, ao positivar o teste, a probabilidade de ser um resultado falso é alta. Significando que não é uma sentença, mas uma atualização de probabilidade. Claro, se você continuar fazendo testes e o resultado continuar sendo positivo, sua chance de ter a doença aumenta bastante: No segundo positivo, 6,24% e no terceiro, 49,3%. Isso motiva a realização de mais testes!\nO problema de Monty Hall Agora, vamos falar do tal carro novo. Mas, antes, eu preciso te preparar: acontece que a situação a seguir é polêmica - causou acaloradas cartas e reações de professores de estatística, quando foi enunciada pela primeira vez, e causou uma acalorada discussão entre eu e minha namorada, quando eu contei pra ela sobre o problema. Prossiga com cuidado ⚠️.\nTudo começa com um quadro de perguntas e respostas em uma revista americana chamado Ask Marilyn. Marilyn vos Savant, reverenciada pelo seu QI altíssimo, respondia dúvidas gerais dos leitores, pense em algo como um google-antes-do-google. Em certo momento chega a seguinte pergunta, inspirada em um famoso programa de TV, Let\u0026rsquo;s make a Deal, apresentado por um carismático host, Monty Hall:\nSuponha que os participantes de um programa de auditório recebam a opção de escolher uma dentre três portas: atrás de uma delas há um carro; atrás das outras, há cabras. Depois que um dos participantes escolhe uma porta, o apresentador, que sabe o que há atrás de cada porta, abre uma das portas não escolhidas, revelando uma cabra. Ele diz ao participante: \u0026ldquo;Você gostaria de mudar sua escolha para a outra porta fechada?\u0026rdquo;. Para o participante, é vantajoso trocar sua escolha?\nTudo que intuitivamente sabemos sobre probabilidades, nos diz o seguinte:\nHá chances iguais do prêmio estar nas três portas, portanto, a probabilidade de prêmio é de 33,3% para cada porta. Uma vez que uma das portas é eliminada, sobram duas portas com iguais probabilidades, portanto, cada uma delas tem uma probabilidade de 50% de conter o prêmio. Como há 50% de chance de acertar a porta, não é vantajoso trocar, nem se manter - ambas opções apresentam o mesmo benefício. Mas - lembrando que a matemática nem sempre é intuitiva - Marylin causou muita confusão ao afirmar que é mais vantajoso trocar a escolha. E não é por pouco, não: você tem 2 vezes mais chance de ganhar o carro, se trocar a porta escolhida. Antes que você, como muitos outros, comece a xingá-la, dizendo que ela não sabe de nada, saiba que sua afirmação está, na verdade, correta. E a estatística Bayesiana pode te ajudar a entender o porquê.\nTudo começa com uma premissa básica: O apresentador, Monty Hall, não está abrindo portas ao acaso. Se fosse o caso, ele correria o risco de abrir a porta do carro, sem querer, o que tira toda a graça do jogo. Então nós precisamos nos atentar ao fato de que ele sabe onde está o carro. Embora isso não mude a percepção intuitiva do problema, pois ainda existem duas portas e um único prêmio, quando colocamos na ponta do lápis, esse detalhe fica bastante relevante.\nSuponha que o participante escolheu a porta 2, ao passo que o apresentador abriu a porta 3, mostrando uma cabra pacientemente comendo um pouco de palha. Como a probabilidade do carro estar atrás da porta de número 1 se altera, diante da nova evidência da porta 3- P(p1|p3)?\nP(p1): Começamos com chances iguais para as três portas, então mantemos esse valor - a probabilidade de que o carro esteja atrás da porta 1 é de 33,3%.\nP(p3|p1): Aqui está o pulo do gato, qual a probabilidade de que a porta 3 seja aberta, caso o prêmio esteja atrás da porta 1?\nO apresentador não pode abrir a porta 2, que você escolheu, porque é contra as regras. O apresentador não pode abrir a porta 1, pois o prêmio está nela e ele não quer revelá-lo. Nesse caso, a única porta que pode ser aberta é a 3, ou seja, essa probabilidade é 100%!\nP(p3): Ignorando agora a localização do prêmio, qualquer uma das duas portas não escolhidas poderiam ser abertas, fazendo com que a probabilidade da porta 3 ser aberta seja 50%.\nCompilando isso tudo na nossa querida formuleta:\n$$ P(p1|p3) = \\frac{P(p3|p1) P(p1)}{P(p3)} = \\frac{0,333 \\times 1}{0,5} = 0,666 $$\nComo vemos, a probabilidade de você ter errado, e o prêmio estar atrás da porta de número 1, é de 66,6%, portanto é mais vantajoso aceitar a troca, ao ser perguntado pelo apresentador. Fazendo as contas para o caso contrário (P(p2|p3)), a probabilidade da porta 3 ser aberta é de 50%, pois o apresentador pode abrir qualquer uma das duas livremente, fazendo assim com que sua chance seja de 1 em 3 - 33,3%.\nNote que esse é um caso particular do teorema. Quando enunciei a fórmula pela primeira vez, a descrevi como uma proporção do evento B, nesse caso específico em que o evento A não influencia o evento B, o evento B também não influencia o evento A - fazendo que que P(B|A) e P(B) se cancelem e P(A|B) seja igual à P(A). Até nisso Bayes foi bem sucedido em formular o bom senso matemáticamente, afinal, não é qualquer coisa que influencia as probabilidades. Não é só porque o Nicolas Cage lançou um filme novo, que mais pessoas vão morrer afogadas (o que não siginifica que não haja uma correlação entre as duas coisas, mas isso é um papo para outro momento).\nConclusão Viver como um ser lógico e estóico não é muito simples, nossa própria mente prega truques ao tentar poupar energia usando o Sistema 1 para responder rapidamente os dilemas do dia-a-dia. Uma boa forma de ativar o Sistema 2 é tentando adicionar a lógica formal e a matemática no seu raciocínio, e o teorema de Bayes é particularmente bom nisso.\nHoje, inclusive, existe quase que um culto à filosofia bayesiana de vida, algumas pessoas realmente norteiam suas vidas usando esse conceito da estatística.\nNão é necessário, no entanto, se inscrever numa seita para tomar decisões melhores, ou interpretar resultados de forma mais correta, usando o teorema. Uma compreensão de que novas evidências atualizam probabilidades antigas, ao invés de substituí-las pode nos levar muito longe, ajudando a desmistificar os viéses cognitivos da nossa mente!\nFontes Bayes theorem, the geometry of changing beliefs, 3Blue1Brown, 2019-12-22 (Acesso em Agosto de 2023).\nRápido e devagar: duas formas de pensar, Daniel Kahneman, 2012.\nO andar do bêbado, Leonard Mlodinow, 2009.\n","permalink":"https://pfalcao97.githubpages.io/blog/posts/estatistica_bayesiana/","summary":"Introdução A matemática é lógica, por definição. Mas isso não significa que ela seja óbvia e, muito menos, intuitiva. Inclusive, muitas vezes, ela é tão pouco óbvia e intuitiva, que nos parece não-lógica. E isso, por si só, é nada intuitivo!\nTanto é, que existe um campo de estudo inteiro dedicado a tratar o ser humano como ente plenamente lógico e racional - a economia - que foi virado de cabeça pra baixo quando dois psicólogos chegaram e falaram \u0026ldquo;Ei, galera, não é bem assim\u0026hellip;\u0026rdquo;.","title":"O prognóstico por representatividade"},{"content":"Introdução Quase todo mundo que está inserido no mundo da programação conhece sobre Expressões Regulares, mas, tão frequente quanto, o conhecimento fica só no \u0026ldquo;sobre\u0026rdquo;, mesmo: o modo de escrita, que beira a criptografia, e a falta de repertório para os casos de uso geram um sentimento generalizado de que RegEx é ~basicamente~ mágica. Mas, diferente de mágica \u0026ldquo;de verdade\u0026rdquo;, conhecer o segredo e estragar a ilusão pode ser muito mais vantajoso.\nClaro, existem necessidades diferentes, que vão desde escrever uma expressão simples para debugar o código no seu editor, até fazer a extração de informações em dados não estruturados, passando por melhorar a legibilidade de uma query no SQL. O que importa é que, com um pouco de sitzfleisch, você pode adicionar mais uma ferramenta no seu arcabouço e se tornar mais produtivo.\nA ideia do texto é apenas molhar seus pés nesse universo, desmistificando o dialeto místico que separa os juniores dos sêniors, a partir de uma compreensão mais palatável.\nPuxando a cortina Para continuar a analogia da mágica, vamos puxar a cortina no meio do espetáculo, tal qual o Mr. M. De forma simples, aquelas instruções escritas em caracteres aparentemente aleatórios são instruções para definir uma máquina de estados finita, basicamente um circuito lógico com estados. Uma boa forma de entender esse conceito é com o exemplo disponível na página da Wikipédia: uma catraca.\nO estado \u0026ldquo;natural\u0026rdquo;, ou inicial, da catraca é travada, você pode tentar empurrar, mas ela continua travada. A partir do momento que você passa o seu cartão com créditos suficiente, a catraca é destravada. Ela fica nesse estado até que você a empurre, fazendo com que ela retorne ao estado natural.\nTá, mas como nós transportamos essa ideia para identificar um texto?\nVou responder isso usando um exemplo: suponha que você deseje criar uma dessas máquinas de estados finita que reconheça palavras entre aspas. Nesse caso, nós teremos três estados:\nEstado inicial: vamos percorrer nosso texto, caracter a caracter, começando aqui. Esse estado indica, efetivamente, que estamos começando uma nova busca. Só iremos passar pro próximo, caso encontremos o caracter \u0026quot; (aspas duplas). Estado intermediário: encontramos o início, agora precisamos achar o fim. Tudo que for letra encontrada pelo caminho não altera o estado, a única coisa capaz de fazer com que nós passemos de estado é, novamente, o caracter \u0026ldquo;. Estado final: se chegamos até aqui, significa que tivemos um match, ou seja, encontramos a combinação de caracteres capaz de percorrer todo o nosso algoritmo e podemos retornar esse texto. Para exercitar a imaginação, eu gosto de pensar em uma setinha em cima das letras, conforme percorremos o texto. A seta indica qual estado estamos, dizendo algo do tipo \u0026ldquo;Isso é um A, não é um caracter que muda o meu estado\u0026rdquo; ou \u0026ldquo;Epa, encontrei uma aspa dupla, muda de estado e vamos esperar para encontrar a próxima\u0026rdquo;, como na ferramenta Regexp::Debugger. [1]\nProgramaticamente, poderíamos fazer algo similar da seguinte forma:\nestado = 1 # Estado inicial match = \u0026#39;\u0026#39; # Nosso match for caracter in texto: # Faz um loop, letra a letra, pelo texto if estado == 2: # Caso estejamos no estado intermediário, match += caracter # adiciona o caracter à variável de match if caracter == \u0026#39;\u0026#34;\u0026#39;: # Se encontrar uma aspa dupla, estado += 1 # muda de estado if estado != 3: # A menos que o estado seja o final, match += caracter # adiciona o caracter à variável de match Embora essas representações deixem a intenção mais clara, a dificuldade de desenhar diagramas de máquinas de estados finitas para cada caso (particularmente os mais complexos) se tornou um problema. Mas o criador das expressões regulares, Stephen Kleene, deu um jeito de abreviar isso, gerando a forma como escrevemos expressões regulares hoje. Todas as linhas de código poderiam ser substituído por uma única linha:\nimport re match = re.search(\u0026#39;\u0026#34;.*\u0026#34;\u0026#39;, texto).group() Bem mais compacto, né?\nPois então, se definirmos o seguinte texto:\ntexto = \u0026#34;\u0026#34;\u0026#34;Este é um exemplo de texto que contém \u0026#34;aspas duplas\u0026#34;!\u0026#34;\u0026#34;\u0026#34; Os dois códigos resultam no mesmo valor para a variável match:\n\u0026ldquo;aspas duplas\u0026rdquo;\nNota do autor: re é a biblioteca nativa de expressões regulares do Python. A documentação está nas fontes, no final da página. 😉\nO beabá do RegEx Agora você pode dizer: \u0026ldquo;Tá, muito legal, muito interessante, mas isso não me ajuda em nada a escrever RegEx\u0026rdquo;. Sim, verdade, mas é importante construir essa intuição antes de começar a estudar de fato, porque assim tem menos decoreba e mais compreensão.\nSe eu tiver feito bem o meu trabalho, quando eu escrevi o RegEx ali em cima (\u0026quot;.*\u0026quot;), você achou legal como ele resume tanta coisa. E a ideia é continuar nesse mote, ao invés de você olhar um asterisco e falar \u0026ldquo;Que merda é essa?!\u0026rdquo;, eu espero que você, no mínimo, reconheça seu poder sintetizador.\nPois bem, nessa linha, existem duas classes que podem definir um caracter numa expressão regular:\nLiteral: é quando o caracter representa ele próprio. A é A. Se você quer saber se a palavra \u0026ldquo;Paçoca\u0026rdquo; aparece no texto, basta usar a própria palavra. Reservado: um caracter é reservado, ou especial, quando o seu significa surpassa o seu simbolo, um bom exemplo é o já mencionado asterisco, que representa a repetição de um caracter \u0026ldquo;zero ou mais vezes\u0026rdquo;. Ou seja, um RegEx como b*dá match com \u0026rsquo; \u0026lsquo;, \u0026lsquo;b\u0026rsquo;, \u0026lsquo;bb\u0026rsquo;, \u0026lsquo;bbb\u0026rsquo; e assim por diante. Às vezes, você precisa usar um caracter reservado como literal, para isso usamos a barra invertida \\. Ou seja, para usar o asterisco como asterisco, e não como \u0026ldquo;zero ou mais vezes\u0026rdquo;, basta colocar \\*.\nMas o que acontece se a gente usar a barra invertida em um literal?\nBom, na maioria das vezes, nada. Mas algumas combinações são, pasmem, boas sintetizadoras. Por exemplo, caso você queira encontrar um número de um digito, ou seja 0 ou 1 ou 2 ou\u0026hellip; ou 9. Você pode fazer um RegEx assim:\nre.search(\u0026#39;0|1|2|3|4|5|6|7|8|9\u0026#39;, texto).group() # A barra vertical, |, indica \u0026#34;ou\u0026#34;. Ou você pode usar \\d - Qualquer digito numérico. Claro, quem conhece um pouquinho de RegEx deve estar me xingando pela forma acima, que nunca seria utilizada, sendo preferível a forma mais compacta: [0-9]. Mas eu prometo que não vou deixar ponto sem nó, tudo tem um motivo (sim, até o \u0026quot;.*\u0026quot;, pros mais avançados).\nE, com isso, a gente já tem os pilares para começar a construir algumas expressões progressivamente mais difíceis.\nVelocidade um na dança do créu Essa primeira parte é a que todo usuário de computador conhece: quando você aperta ctrl+f (ou cmd+f 🍎) para pesquisar uma palavra em uma página da web. Você digita a palavra que você está procurando e ela é grifada na página. É pura e simplesmente o uso de uma expressão literal.\nEmbora isso possa parecer tão óbvio que você talvez nem perceba, esse é um dos casos mais utilizados, na minha experiência. Por exemplo, você está analisando um banco de dados de produtos de moda e quer ver todos os produtos com cor rosa, para fazer um marketing de oportunidade pro filme da Barbie, basta rodar uma query assim:\nSELECT * FROM tabela_produtos WHERE LOWER(nome_produto) LIKE \u0026#39;rosa\u0026#39; Assim nós encontramos aqueles produtos como \u0026ldquo;Camiseta M Básica Rosa\u0026rdquo; ou \u0026ldquo;Salto Alto Rosa\u0026rdquo;. O problema é que muitas vezes o analista não conhece muito de RegEx (ou aprendeu esse \u0026ldquo;truque\u0026rdquo; do LIKE e replica, sem pensar muito no que está fazendo) e a query rapidamente vira uma macarronada com dezenas de linhas fazendo vários filtros de LIKE na mesma coluna.\nPara resolver isso\u0026hellip;\nVelocidade dois na dança do créu Aqui a gente começa a adicionar alguns daqueles caracteres reservados. Seja usando a já mencionada barra vertical ou os colchetes. Por exemplo, em uma lista de cidades com o nome da seguinte forma:\nCidade, Estado (Ex: São Paulo, SP)\nComo podemos contar quantas cidades são da região Norte?\nimport re qtd_cidades_norte = len(re.findall(\u0026#34;AC|AM|AP|PA|RO|RR|TO\u0026#34;, lista_cidades)) Agora, se você quisesse saber quais são essas cidades, fica um pouco mais difícil. No caso do RegEx que eu escrevi ali, ele vai procurar as siglas dos estados no texto e adicionar essas siglas à lista. Por isso ela é útil só pra fazer a contagem. Ou em casos específicos, como quando você é mais liberal com a sua definição da cor rosa:\nSELECT * FROM tabela_produtos WHERE REGEXP_LIKE(nome_produto, \u0026#39;rosa|rox[ao]\u0026#39;, \u0026#39;i\u0026#39;) Parece que eu adicionei muita coisa de uma vez, mas vamos por partes:\nAlém da cor rosa, também vamos procurar as peças com a cor roxa, portanto rosa|roxa. Roxo, porém, é um adjetivo que possui flexões diferentes, conforme o gênero do substantivo (\u0026ldquo;Camiseta Roxa\u0026rdquo; ou \u0026ldquo;Lenço Roxo\u0026rdquo;), diferente do rosa. Assim, precisamos levar em consideração as duas versões. Mas, ao invés de escrever rosa|roxa|roxo, como a raíz \u0026ldquo;rox\u0026rdquo; é igual para as duas palavras, podemos fazer o seguinte: rox[ao], ou seja, \u0026ldquo;Encontre uma palavra que começa com \u0026lsquo;rox\u0026rsquo; e termina com \u0026lsquo;a\u0026rsquo; ou \u0026lsquo;o\u0026rsquo;\u0026rdquo;. Portanto: rosa|rox[ao]. Ao invés de usar o LIKE, eu estou utilizando REGEXP_LIKE, para poder usar a flag i, que indica que não vou fazer diferenciação entre letras maiúsculas e minúsculas. Tá ficando difícil, ein?! Até agora, não escrevemos nada que salte os olhos como especialmente complexo. Mas nesse próximo nível, a gente precisa começar a incluir alguns daqueles símbolos diferentes.\nImagine, por exemplo, que você esteja auxiliando na digitalização de documentos em uma empresa. Alguém já transformou os arquivos físicos em arquivos digitais, porém ainda é preciso colocar alguns desses dados em bases de dados. Uma dessas informações é a data de admissão de todos os colaboradores. A sua chefa acabou de te pedir para fazer isso.\nÉ evidente que esse trabalho não seria tão compartimentado assim, mas, para fim de exemplo, exercite sua suspensão da descrença: você só precisa salvar o nome do arquivo e a data de admissão, depois alguém junta todos os dados do funcionários em uma tabela, usando o nome de arquivo como chave primária.\nO documento é um .txtque toma a seguinte forma:\nNome: Fulano de Tal\nCargo: Engenheiro de Dados\nData de Nascimento: 01/01/1990\nData de Admissão: 01/01/2020\nUma boa forma de começar é pegar só a parte que você quer e garantir que você está conseguindo corresponder com ela. No nosso caso, queremos uma data com o formato DIA/MÊS/ANO, ou seja: dois digitos numéricos + / + dois digitos numéricos + / + quatro digitos numéricos:\nimport re re.search(\u0026#39;\\d\\d/\\d\\d/\\d\\d\\d\\d\u0026#39;, \u0026#39;01/01/2020\u0026#39;).group() Claro, se você já percebeu o modus operandi da ferramenta, há uma forma de simplificar a construção de caracteres iguais repetindo N vezes (quando N é conhecido e fixo, já vimos que para vezes indeterminadas pode se usar o asterisco), usando as chaves, {N}:\nimport re re.search(\u0026#39;\\d{2}/\\d{2}/\\d{4}\u0026#39;, \u0026#39;01/01/2020\u0026#39;).group() As chaves podem, ainda, te dizer o máximo e o mínimo de repetições. Se você soubesse que em alguns casos o início das datas foram omitidos (por exemplo \u0026ldquo;01/01/2020\u0026rdquo; sendo escrito como \u0026ldquo;1/1/20\u0026rdquo;), você poderia colocar a quantidade mínima e máxima de repetições que você espera ver, usando a síntaxe {Número mínimo de repetições, Número máximo de repetições}:\nimport re re.search(\u0026#39;\\d{1,2}/\\d{1,2}/\\d{2,4}\u0026#39;, \u0026#39;01/01/2020\u0026#39;).group() Só tem um problema\u0026hellip; Da mesma forma que o código funciona para a data desejada, também funciona para \u0026ldquo;99/99/9999\u0026rdquo;, que, obviamente, não é uma data. Se você tiver certeza que tudo está corretamente digitalizado, você poderia apenas usar o RegEx acima, mas é possível encontrar erros de digitalização se você restringir um pouco o código: sabemos que os dias só podem começar com 0, 1, 2 ou 3, que os meses só podem começar com 0 ou 1 e que o ano só pode começar com 1 ou 2 (ou só 2, caso sua empresa tenha sido fundada depois do ano 2000), portanto podemos deixar nosso RegEx mais robusto (e confiável) da seguinte forma:\nimport re re.search(\u0026#39;[0123]{0,1}\\d/[01]{0,1}\\d/[12]{0,1}\\d{2,3}\u0026#39;, \u0026#39;01/01/2020\u0026#39;).group() Agora tá começando a ficar com uma carinha legal, né?\nDepois disso fica fácil, a gente só precisa garantir que o RegEx pega a data de admissão e não a de nascimento, mas para isso basta usar o texto literal, que é estático:\nimport re re.search(\u0026#39;Data de Admissão: [0123]{0,1}\\d/[01]{0,1}\\d/[12]{0,1}\\d{2,3}\u0026#39;, \u0026#39;Data de Admissão: 01/01/2020\u0026#39;).group() Bom, na verdade, quase basta, porque se usarmos esse código, ele vai trazer inclusive o texto \u0026ldquo;Data de Admissão: \u0026ldquo;, que nós não queremos. Para separar o joio do trigo, nós podemos utilizar grupos. Nesse caso, é possível adicionar um grupo de captura, usando o parênteses em torno da data. Aí sim, temos o código completo para automatizar esse processo:\nfrom os import listdir from re import search lista_de_datas = list() diretorio = \u0026#34;/caminho/\u0026#34; # Caminho da pasta com os arquivos for documento in listdir(diretorio): if \u0026#39;.txt\u0026#39; in documento: # Lê os documentos with open(diretorio + documento, \u0026#39;r\u0026#39;) as lupa: texto = lupa.read() # Salva o nome do documento e a data de admissão em # uma tupla, e essa tupla em uma lista lista_de_datas.append( (documento, search(\u0026#39;Data de Admissão: ([0123]{0,1}\\d/[01]{0,1}\\d/[12]{0,1}\\d{2,3})\u0026#39;, texto).group(1)) ) créu créu créu créu créu\u0026hellip; (créu )* 😆 Tocamos brevemente no último ponto que quero fazer, na seção anterior: o poder do RegEx como validador. Qualquer um que já teve a oportunidade de cuidar de um banco de dados com dados digitados por usuário (como dados de cadastro), teve a experiência única de descobrir que pessoas que nasceram em 1822, ou que vão nascer em 3034, são compradoras frequentes da sua loja.\nO ponto é: essas informações não são sempre confiáveis.\nNota do Autor: esta é uma obra de ficção. Os personagens, acontecimentos e nomes retratados são inventados e qualquer semalhança com a realidade é mera coincidência\nMas nós podemos melhorar isso com uma camada de validação no cadastro: por que aceitar um dado que nós já sabemos que é errado? Validadores de CPF, por exemplo, são tão comuns que viraram exercício para estudantes de programação. Por que não fazer o mesmo com validadores de outras informações, como emails e números de telefone, para estudantes de RegEx?\nNa verdade, até tem um porquê\u0026hellip; Eu preciso ser sincero: a validação de email usando RegEx é incompleta e extremamente confusa, por alguns motivos:\nDa mesma forma que um CPF estar no formato válido, não garante a existência dele, um email válido não necessariamente existe. Para checar isso, é necessário o uso de outras ferramentas. Existem muitas formas de emails válidos, principalmente formas que nós não temos contato no dia-a-dia, que são raras e diferentes, mas\u0026hellip; MAS você entrar o seu email corretamente e o site não aceitar, porque um programador teve preguiça na hora de fazer um RegEx, é uma das piores experiências possíveis para um usuário. Recomendo evitar, se você quiser mantê-lo como cliente. Para um RegEx que obedeça às normas oficiais (pelo menos na época em que foi escrita - Não, eu não chequei), dê uma olhada na referência [2]. Mas, aqui, vamos prezar pelo simples:\nO usuário pode ter letras maiúsculas ou minúsculas, números, \u0026ldquo;.\u0026rdquo;, \u0026ldquo;-\u0026rdquo; e \u0026ldquo;_\u0026rdquo;.\nO servidor será apenas de alto nível e contendo apenas letras (isso significa que vamos ignorar o IP do servidor).\nIgualmente, vamos manter só domínios \u0026ldquo;.com\u0026rdquo;.\nAntes de prosseguir, quero só enfatizar mais uma vez: estou mais preocupado com o didatismo, use o código abaixo com parcimônia. Se você quer algo um pouco mais completo, esse site clama ter códigos que funcionam 99,99% das vezes (Mas, ainda assim, a palavra de ordem é ✨ parcimônia ✨. Experiência do usuário é importante).\nO fim é mais fácil, então comecemos por ele:\nimport re re.search(\u0026#34;@[a-z]+.com$\u0026#34;, \u0026#39;@servidor.com\u0026#39;).group() Os principais servidores comerciais são contemplados por essa regra, que diz, basicamente: Encontre um texto que começa com o \u0026ldquo;@\u0026rdquo;, depois tem uma ou mais (uma ou mais está representado pelo +) letras minúsculas até encontrar o termo \u0026ldquo;.com\u0026rdquo;, que é a última parte do texto (representado pelo cifrão).\nEm cima disso, precisamos adicionar a parte do usuário, que é um pouco menos restritiva, pois ela pode conter letras maiúsculas [A-Z] ou minúsculas [a-z], números [0-9], o ponto, o hífen e a barra inferior.\nimport re re.search(\u0026#34;^[a-zA-Z0-9_\\.-]+@[a-z]+.com$\u0026#34;, \u0026#39;fulano.detal90@servidor.com\u0026#39;).group() Fizemos algo bem parecido, mas, ao invés de considerar o fim do texto, $, estamos considerando o início, ^, e ao invés de considerarmos só as letras minúsculas, temos uma ou mais (+) de qualquer dos caracteres citados. Esse RegEx é muito bom para enxugar uma lista de emails que vai ser usada em CRM, apesar de não ser tão boa para validação.\nE talvez você esteja achando estranho o tom tão preocupado que estou tendo em relação à validação. Não é impressão sua, o tom é propostial e eu vou te contar o porquê\u0026hellip;\nTamanho é documento, SIM! Lembra que comentei que eu não ia deixar ponto sem nó? Então, se você é um bom aluno (🤓) e estiver testando junto com o texto, pode ter percebido que o \u0026quot;.*\u0026quot;funciona, pero no mucho. Porque, no exemplo cuidadosamente selecionado que dei, é uma maravilha, mas se você coloca duas frases com aspas duplas, dá tudo errado. Por que? Eu menti pra você?!\nExiste mais de uma forma para chegar ao seu objetivo com RegEx e, a bem da verdade, existem formas melhores e piores. Essa que eu sugeri, é uma das piores, porque o asterisco é um modificador ganancioso, isso significa que ele pega o máximo de caracteres possíveis. Para o momento, ele estava mais do que suficiente, mas, depois de tudo que passamos juntos, acho que eu posso ter uma conversa mais séria com você.\nEscrever um bom RegEx é sinônimo de muitos testes e pensar fora da caixa, porque é preciso ver se ele funciona em todas as situações em que você precisa que ele funcione e, tão importante quanto, não funcione quando você precise que ele não funcione. Há, ainda, que se considerar a performace. Por isso, no geral, Expressões regulares mais completas e mais longas, são melhores. Se você tomar atalhos, sua performace, sua segurança ou os dois, podem sofrer.\nFoi exatamente isso que aconteceu com a Cloudflare, em 2019. Vale a pena a leitura da descrição completa do problema no blog deles ([3]), especialmente se você se interessa por segurança, mas o resumo da opera é:\nUm engenheiro escreveu um código RegEx para o WAF (Web Application Firewall) do serviço. WAF é um firewall específico para chamadas HTTP, que visa proteger os serviços de ataques maliciosos como SQL Injection ou outras formas de interagir com o servidor usando comandos \u0026ldquo;escondidos\u0026rdquo; na query. O código era esse: (?:(?:\u0026quot;|\u0026rsquo;|]|}|\\|\\d|(?:nan|infinity|true|false|null|undefined|symbol|math)|`|-|+)+[)];?((?:\\s|-|~|!|{}||||+).(?:.=.*)))\nPela natureza desse tipo de ação, que deve ser rápida para impedir que O Mais Novo Cyber Ataque™️ cause estragos, alguém escreve um código, há uma validação entre o time de engenharia, que aceita o Pull Request e o commit é feito, sendo implementado em todos os servidores ao redor do globo em segundos, sem, naquele momento, todas as precauções necessárias.\nNão haviam travas ou testes de consumo de CPU para barrar o RegEx, apenas testes de detecção, isso fez que o código mal otimizado, particularmente .*.*=.*, exigisse muito do CPU do servidor, para toda nova requisição. Em poucos minutos essa regra fritou os servidores globais da CloudFlare, deixando vários serviços fora do ar.\nO que aconteceu foi, basicamente, uma regra perigosa (Procure qualquer coisa de qualquer tamanho, seguida de qualquer coisa de qualquer tamanho, seguida de um igual, seguida de qualquer coisa de qualquer tamanho) e a falta de testes suficientes gerando um problema de escala global.\nO perigo nesse tipo de regra é conhecido, damos a ele o nome Catastrophic Backtracking (Em tradução livre, seria algo como Marcha-ré Catastrófica): a regra é escrita de uma maneira que o motor RegEx precisa checar múltiplas vezes uma mesma palavra, para verificar a existência de correspondências.\nPor isso a ênfase que estou tendo, particularmente em códigos de validação, é preciso testes e travas que protejam o ambiente contra essas situações catastróficas, além da tal parcimônia na hora de escrever os códigos, sempre pensando em situações limite.\nConclusão As expressões regulares são uma das ferramentas mais poderosas na programação, ela pode, literalmente, transformar sua vida em um inferno ou agilizar seu trabalho em muitas vezes. Embora eu não espere que você saia desse texto com a capacidade de escrever um código RegEx capaz de encontrar números primos (recomendo demais olhar isso, é uma das coisas mais legais que já vi feitas com RegEx - [4]), eu espero que ele tenha sido útil para, ao menos, desmistificar os códigos e te incentivar a finalmente estudar.\nCitações [1] - Watch RegExes with Regexp::Debugger\n[2] - Mail::RFC822::Address: RegExp-based address validation [3] - How Regular Expressions and a WAF DoS-ed Cloudflare\n[4] - A regular expression to check for prime numbers\nFontes Regular Expressions, Computerphile, 2020-01-09. (Acesso em Julho de 2023)\nTutorial, RegExp.info (Acesso em Julho de 2023)\nDocumentação re, Python Software Foundation (Acesso em Julho de 2023)\nDocumentação do PostgreSQL, PostgreSQL Global Developmente Group (Acesso em Julho de 2023)\nUnder the Hood: Regular Expressions, Reindeer Effect, 2018-06-24 (Acesso em Julho de 2023)\nRegexes: The Bad, the Better, and the Best, Liz Bennett, 2015-06-18 (Acesso em Julho de 2023)\n","permalink":"https://pfalcao97.githubpages.io/blog/posts/regex/","summary":"Introdução Quase todo mundo que está inserido no mundo da programação conhece sobre Expressões Regulares, mas, tão frequente quanto, o conhecimento fica só no \u0026ldquo;sobre\u0026rdquo;, mesmo: o modo de escrita, que beira a criptografia, e a falta de repertório para os casos de uso geram um sentimento generalizado de que RegEx é ~basicamente~ mágica. Mas, diferente de mágica \u0026ldquo;de verdade\u0026rdquo;, conhecer o segredo e estragar a ilusão pode ser muito mais vantajoso.","title":"Expressões Regulares"},{"content":"Pedro Falcão Engenheiro de Dados @ Descomplica 🇧🇷\nSobre mim: Sou formado em Engenharia Mecânica, pela Universidade de São Paulo, mas, desde antes disso, trabalho com dados. Comecei a aprender conceitos de Python e aprendizado de máquina desde meu primeiro ano da universidade, em 2017, e desde então meu interesse por programação sempre cresceu. Minha maior paixão é compartilhar conhecimento, então, por muitos anos, trabalhei na construção de projetos que poderiam me ajudar com esse objetivo, incluindo dar aulas e escrever um blog de comunicação científica. Atualmente, a maior parte do meu tempo livre é voltada para adquirir conhecimento que me permita criar um canal para o ensino de conceitos em STEM (Sigla em inglês que significa Ciência, Tecnologia, Engenharia e Matemática). Tenho muitos planos para o futuro e espero compartilhar tudo isso em breve.\nSou apaixonado pela filosofia Open Source e tento usar e dar suporte ao movimento FOSS sempre que possível, portanto, estou aberto a contribuir com qualquer projeto desse tipo. Além disso, adoraria ajudar em projetos mais focados em matemática (como problemas de otimização e simulações) e análise de dados. Se quiser conversar é só me chamar no meu LinkedIn!\nDesenvolvimento: Meu trabalho é como Engenheiro de Dados, em uma empresa brasileira de educação, Descomplica. Trabalho diariamente com sistemas Python, SQL, GCP, Bash, Docker, Airflow e UNIX. Também estou aprendendo Rust no meu tempo livre, então isso pode aparecer de vez em quando aqui! Como comentei, já trabalhei profissionalmente no desenvolvimento de (mas não somente) sistemas de dados, então, em meu currículo, tenho dezenas de projetos em automação, otimização de processos, Extração-Tratamento- Carregamento de pipelines, Escrita de relatórios complexos de análise de dados, criação de projetos de Machine Learning, desenvolvimento de algoritmos, criação de bots (para plataformas como Telegram e Slack) e visualização de dados. Também trabalhei em pequenos projetos para mim, especialmente análise de dados e automação.\nUm projeto em que trabalhei em meu tempo livre, do qual estou particularmente orgulhoso, foi automatizar um pipeline que consiste em extrair dados não estruturados de um arquivo PDF (incluindo transformá-lo em um arquivo de texto e, em seguida, desenvolver vários códigos RegEx complexos para obter exatamente os dados que me interessam - Trabalhar com PDFs é notoriamente difícil), tratá-los, porque eles tinham vários formatos de data e mais de uma moeda e, finalmente, carregá-los em uma planilha do Excel. Este processo foi feito para automatizar um problema de trabalho comum para minha adorável namorada advogada. Postâmbulo: Ok, então isso era tudo que eu tinha para dizer que era minimamente interessante. Agora, a parte que você pode pular sem se preocupar: Meus gostos e desgostos!\nNa maioria das vezes, estou fazendo o que descrevi nas outras seções, mas também mexo regularmente com equipamentos de áudio e impressão 3D. Tenho uma impressora 3D Ender 3, que uso para resolver pequenas inconveniências na vida das pessoas ao meu redor e uma infinidade de equipamentos de áudio, meu IEM favorito é o Ikko OH10 (ou Obsidian). Gosto de malhar e correr/caminhar pela cidade. Também adoro jogar videogame, embora isso não seja algo que eu tenha tanto tempo hoje em dia, entre os meus jogos favoritos, posso citar Disco Elysium, Half-Life e Deus Ex. Meu seriado preferido é Seinfeld, com quem, segundo aquela linda namorada de quem falei, compartilho muitos maneirismos. Eu tento ler todos os dias antes de dormir e meu gênero favorito é a comunicação científica.\n","permalink":"https://pfalcao97.githubpages.io/blog/aboutme/","summary":"Pedro Falcão Engenheiro de Dados @ Descomplica 🇧🇷\nSobre mim: Sou formado em Engenharia Mecânica, pela Universidade de São Paulo, mas, desde antes disso, trabalho com dados. Comecei a aprender conceitos de Python e aprendizado de máquina desde meu primeiro ano da universidade, em 2017, e desde então meu interesse por programação sempre cresceu. Minha maior paixão é compartilhar conhecimento, então, por muitos anos, trabalhei na construção de projetos que poderiam me ajudar com esse objetivo, incluindo dar aulas e escrever um blog de comunicação científica.","title":""}]